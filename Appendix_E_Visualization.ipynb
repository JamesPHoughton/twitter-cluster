{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix E: Visualization\n",
    "\n",
    "Visualizations will use the following python librarires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import itertools\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define several helper functions to assist with reading the cluster files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_named_cluster_file(infile_name):\n",
    "    \"\"\" take a file output from COS and return a dictionary, \n",
    "    where keys are the name of a cluster, \n",
    "    and values are sets containing names of nodes in the cluster\"\"\"\n",
    "    clusters = dict()\n",
    "    with open(infile_name, 'r') as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            name = line.split(' ')[0]\n",
    "            if not clusters.has_key(name):\n",
    "                clusters[int(name)] = set()\n",
    "            nodes = line.split(' ')[1:-1]\n",
    "            for node in nodes:\n",
    "                clusters[int(name)].add(node)\n",
    "    return clusters  \n",
    "\n",
    "\n",
    "def get_clusters_with_keyword(date, threshold, keyword):\n",
    "    \"\"\"Get clusters from the dataset that include the keyword.\n",
    "    Get them for the specified date and threshold.\n",
    "    \n",
    "    date : string in yyyymmdd format\n",
    "    threshold : integer above 2\n",
    "    \n",
    "    \"\"\"\n",
    "    files = pd.DataFrame(glob.glob(date+'/th_%02i'%threshold+'/named*_communities.txt'), columns=['filename'])\n",
    "    files['clique_size']=files['filename'].apply(lambda x: int(x.split('named')[1].split('_')[0])) #brittle\n",
    "    files.sort('clique_size', ascending=False, inplace=True)\n",
    "\n",
    "    outlist = []\n",
    "    \n",
    "    for index, row in files.iterrows():\n",
    "        clusters = read_named_cluster_file(row['filename'])\n",
    "        for index, cluster_set in clusters.iteritems():\n",
    "            outdict = {}\n",
    "            if keyword in cluster_set:\n",
    "                outdict['date'] = date\n",
    "                outdict['threshold'] = threshold\n",
    "                outdict['keyword'] = keyword\n",
    "                outdict['elements'] = cluster_set\n",
    "                outdict['k-clique'] = row['clique_size']\n",
    "                outdict['name'] = index\n",
    "                outdict['id'] = str(date)+'_k'+str(row['clique_size'])+'_t'+str(threshold)+'_i'+str(index)\n",
    "                outdict['size'] = len(cluster_set)\n",
    "                outlist.append(outdict)\n",
    "    return pd.DataFrame(outlist)\n",
    "\n",
    "\n",
    "def get_next_clusters(clustersdf, min_likelihood=0):\n",
    "    \"\"\"Returns a new clustersdf for the subsequent day\n",
    "    and a transition matrix between the input and output clustersdf.\n",
    "    \n",
    "    min_likelihood sets a lower bar on the chance that a next-day cluster is the\n",
    "    same as the previous-day cluster\"\"\"\n",
    "    \n",
    "    outlist=[]    \n",
    "    transitions = pd.DataFrame()\n",
    "    for i, row in clustersdf.iterrows():\n",
    "        current_date = row['date']\n",
    "        next_date = dates[dates.index(current_date)+1]\n",
    "        \n",
    "        tr_file = '%s/th_%02i/named%i_communities_transition.csv'%(current_date, \n",
    "                                                                   row['threshold'],\n",
    "                                                                   row['k-clique'])\n",
    "        tr_matrix = pd.read_csv(tr_file, index_col=0)\n",
    "        \n",
    "        shared_elements = tr_matrix.loc[int(row['name'])]\n",
    "        candidate_names = shared_elements[shared_elements>0].index\n",
    "        \n",
    "        next_clusters_filename = '%s/th_%02i/named%i_communities.txt'%(next_date,\n",
    "                                                                       row['threshold'],\n",
    "                                                                       row['k-clique'])\n",
    "        next_clusters = read_named_cluster_file(next_clusters_filename)\n",
    "            \n",
    "        for name in candidate_names:\n",
    "            outdict = {'date':next_date,\n",
    "                       'threshold':row['threshold'],\n",
    "                       'elements':next_clusters[int(name)],\n",
    "                       'k-clique':row['k-clique'],\n",
    "                       'name':name,\n",
    "                       'size':len(next_clusters[int(name)]),\n",
    "                       'id':(str(next_date)+'_k'+str(row['k-clique'])+\n",
    "                             '_t'+str(row['threshold'])+'_i'+str(name))}\n",
    "\n",
    "            total_elements = set(next_clusters[int(name)]) | set(row['elements'])\n",
    "            likelihood = 1.0*shared_elements[name]/len(total_elements) #normalizing here...\n",
    "            if likelihood > min_likelihood:\n",
    "                outlist.append(outdict)\n",
    "                transitions.loc[row['id'], outdict['id']] = likelihood\n",
    "\n",
    "    return pd.DataFrame(outlist).drop_duplicates('id'), transitions.fillna(0)\n",
    "\n",
    "\n",
    "def cluster_post_volume(cluster):\n",
    "    \"\"\" Returns the volume of posts that contribute to the cluster, \n",
    "    by combination. This is a dataframe of \n",
    "    \n",
    "    \n",
    "    You can then take the max, min, mean, etc.\"\"\"\n",
    "    \n",
    "    weighted_edgelist_file = '%s/weighted_edges_%s.txt'%(str(cluster.loc['date']),str(cluster.loc['date']))\n",
    "    df = pd.read_csv(weighted_edgelist_file, sep=' ', header=None, names=['Tag1', 'Tag2', 'count'])\n",
    "\n",
    "    collect = []\n",
    "    for a, b in itertools.combinations(list(cluster.loc['elements']), 2):\n",
    "        count =  df[((df['Tag1']==a) & (df['Tag2']==b))|((df['Tag1']==b) & (df['Tag2']==a))]['count'].sum()\n",
    "        collect.append({'Tag1':a, 'Tag2':b, 'count':count})\n",
    "        \n",
    "    return pd.DataFrame(collect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class object to aggregate the information needed to generate a plot of the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cluster_drawing(object):\n",
    "    text_properties = {'size':12,\n",
    "                       'fontname':'sans-serif',\n",
    "                       'horizontalalignment':'center'}\n",
    "    \n",
    "    \n",
    "    def __init__(self, contains, uid=None):\n",
    "        if isinstance(contains, (set,frozenset)): #convenience conversion of set to list.\n",
    "            contains = list(contains)\n",
    "            \n",
    "        if isinstance(contains, list):\n",
    "            self.is_leaf = False\n",
    "            self.contents = []\n",
    "            for element in contains:\n",
    "                if isinstance(element, basestring):\n",
    "                    self.contents.append(cluster_drawing(element))\n",
    "                else:\n",
    "                    self.contents.append(element)\n",
    "            self.linewidth = 1\n",
    "        elif isinstance(contains, basestring):\n",
    "            self.is_leaf = True\n",
    "            #self.text = contains.encode('ascii', 'ignore')\n",
    "            self.text = contains\n",
    "            self.text = contains.decode('utf-8', 'ignore')\n",
    "            self.linewidth = 0\n",
    "        \n",
    "        self.bottom = 0\n",
    "        self.center = 0\n",
    "        self.pts_buffer = 4\n",
    "        self.uid = uid\n",
    "        \n",
    "    def get_list(self):\n",
    "        if self.is_leaf:\n",
    "            return [self.text]\n",
    "        else:\n",
    "            return [item for x in self.contents for item in x.get_list()] #flat list\n",
    "        \n",
    "    def get_set(self):\n",
    "        return set(self.get_list())\n",
    "        \n",
    "    def get_by_name(self, name):\n",
    "        if self.is_leaf: return None\n",
    "        \n",
    "        if self.uid == name:\n",
    "            return self\n",
    "        else:\n",
    "            for x in self.contents:\n",
    "                obj = x.get_by_name(name)\n",
    "                if obj == None:\n",
    "                    continue\n",
    "                else:\n",
    "                    return obj\n",
    "        return None\n",
    "    \n",
    "    def get_uids(self):\n",
    "        if self.is_leaf:\n",
    "            return []\n",
    "        else:\n",
    "            uid_list = [item for x in self.contents for item in x.get_uids()] #flat list\n",
    "            if self.uid != None:\n",
    "                uid_list.append(self.uid)\n",
    "            return uid_list\n",
    "    \n",
    "    def score(self):\n",
    "        \"\"\"Get the score for the full (recursive) contents\"\"\"\n",
    "        score=0\n",
    "        this_list = self.get_list()\n",
    "        for word in set(this_list):\n",
    "            indices = [i for i, x in enumerate(this_list) if x == word]\n",
    "            if len(indices)>1:\n",
    "                score += sum([abs(a-b) for a, b in itertools.combinations(indices, 2)]) \n",
    "        return score\n",
    "    \n",
    "    def order(self, scorefunc):\n",
    "        \"\"\"Put the contents in an order that minimizes the score of the whole list\"\"\"\n",
    "        if not self.is_leaf:\n",
    "            best_score = 10000000\n",
    "            best_order = self.contents\n",
    "            for permutation in itertools.permutations(self.contents):\n",
    "                self.contents = permutation\n",
    "                new_score = scorefunc()\n",
    "                if new_score < best_score:\n",
    "                    best_score = new_score\n",
    "                    best_order = permutation\n",
    "            self.contents = best_order\n",
    "\n",
    "            [element.order(scorefunc) for element in self.contents]\n",
    "        \n",
    "    \n",
    "    def set_height(self, ax):\n",
    "        if self.is_leaf:\n",
    "            #have to mockup the actual image to get the width\n",
    "            self.image_text = ax.text(0, 0, self.text, **self.text_properties)\n",
    "            plt.draw()\n",
    "            extent = self.image_text.get_window_extent()\n",
    "            self.height = extent.y1 - extent.y0      \n",
    "        else:\n",
    "            self.height = (sum([x.set_height(ax) for x in self.contents]) + \n",
    "                           (len(self.contents)+1)*self.pts_buffer)\n",
    "        return self.height\n",
    "    \n",
    "    def set_width(self, ax):\n",
    "        if self.is_leaf:\n",
    "            #have to mockup the actual image to get the width\n",
    "            self.image_text = ax.text(0, 0, self.text, \n",
    "                                           transform=None, **self.text_properties)\n",
    "            plt.draw()\n",
    "            extent = self.image_text.get_window_extent()\n",
    "            self.width = extent.x1 - extent.x0 + self.pts_buffer      \n",
    "        else:\n",
    "            self.width = max([x.set_width(ax) for x in self.contents]) + 2*self.pts_buffer\n",
    "        return self.width\n",
    "                \n",
    "    def set_center(self, x):\n",
    "        if not self.is_leaf:\n",
    "            [child.set_center(x) for child in self.contents]            \n",
    "        self.center = x\n",
    "\n",
    "        \n",
    "    def set_bottom(self, bottom=0):\n",
    "        \"\"\"Sets the bottom of the box.\n",
    "        recursively sets the bottoms of the contents appropriately\"\"\"\n",
    "        self.bottom = bottom + self.pts_buffer\n",
    "        \n",
    "        if not self.is_leaf:\n",
    "            cum_height = self.bottom\n",
    "            for element in self.contents:\n",
    "                element.set_bottom(cum_height)\n",
    "                cum_height += element.height + self.pts_buffer\n",
    "        \n",
    "    def layout(self, ax):\n",
    "        if not self.is_leaf:\n",
    "            [child.layout(ax) for child in self.contents]\n",
    "        \n",
    "        plt.box('off')\n",
    "        self.set_width(ax)\n",
    "        self.set_height(ax)\n",
    "        ax.clear()\n",
    "        \n",
    "    def draw(self,ax):\n",
    "        if not hasattr(self, 'width'):\n",
    "            print 'Must run `layout` method before drawing, preferably with dummy axis'\n",
    "        \n",
    "        if self.is_leaf:\n",
    "            self.image_text = ax.text(self.center, self.bottom, self.text, \n",
    "                                           transform=None, **self.text_properties)\n",
    "        else:\n",
    "            [child.draw(ax) for child in self.contents]\n",
    "            ax.add_patch(plt.Rectangle((self.center-.5*self.width,self.bottom), \n",
    "                                              self.width, self.height,\n",
    "                                              alpha=.1, transform=None))\n",
    "        ax.set_axis_off()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define several functions which intermediate between the visualization object and the clusters as they have been imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_elements(clustersdf, k_min=0, k_max=25, order=False):  \n",
    "\n",
    "    prev_elements =[]\n",
    "    for k, k_group in clustersdf.groupby('k-clique', sort=False):\n",
    "        if k<k_min: continue\n",
    "        if k>k_max: continue\n",
    "        elements = []\n",
    "        for i, row in k_group.iterrows():\n",
    "            cluster_elements = row['elements']\n",
    "            cluster_list = [] #this is what we will eventually pass to the class initialization\n",
    "            for prev_element in prev_elements:\n",
    "                prev_set = prev_element.get_set()\n",
    "                if prev_set <= cluster_elements: #set 'contains'\n",
    "                    cluster_elements = cluster_elements - prev_set\n",
    "                    cluster_list = cluster_list + [prev_element]\n",
    "\n",
    "            cluster_list = cluster_list + list(cluster_elements)\n",
    "            elements.append(cluster_drawing(cluster_list, row['id']))\n",
    "\n",
    "        prev_elements = elements\n",
    "        \n",
    "    a = cluster_drawing(elements)\n",
    "    if order:\n",
    "        a.order(a.score)\n",
    "    return a\n",
    "            \n",
    "    \n",
    "    \n",
    "def draw_transition(a, b, tr_matrix, ax):\n",
    "    for a_id in a.get_uids():\n",
    "        for b_id in b.get_uids():\n",
    "            try:\n",
    "                likelihood = tr_matrix.loc[a_id, b_id]\n",
    "            except KeyError: # if either don't show up in the transition matrix, they don't have a corresponding cluster\n",
    "                continue \n",
    "            if likelihood > 0:\n",
    "                #print a_id, b_id, likelihood\n",
    "                a_object = a.get_by_name(a_id)\n",
    "                b_object = b.get_by_name(b_id)\n",
    "\n",
    "                ax.plot([a_object.center+.5*a_object.width, b_object.center-.5*b_object.width],\n",
    "                         [a_object.bottom, b_object.bottom], \n",
    "                         color='b', alpha=likelihood**2, transform=None)\n",
    "                \n",
    "                ax.plot([a_object.center+.5*a_object.width, b_object.center-.5*b_object.width],\n",
    "                         [a_object.bottom+a_object.height, b_object.bottom+b_object.height], \n",
    "                         color='b', alpha=likelihood**2, transform=None)\n",
    "                \n",
    "    ax.set_axis_off()\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to make a visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,23))\n",
    "ax = plt.gca()\n",
    "ax_test = ax.twinx()\n",
    "\n",
    "prev_elements = None\n",
    "transition = None\n",
    "k_min=4\n",
    "\n",
    "current_df = cu.get_clusters_with_keyword(date='20150618', threshold=5, keyword='charleston')\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    center = 200*i+200\n",
    "    bottom = 120\n",
    "    current_elements = cu.make_elements(current_df, k_min=k_min)\n",
    "    current_elements.layout(ax_test)\n",
    "    current_elements.set_bottom(bottom)\n",
    "    current_elements.set_center(center)\n",
    "    current_elements.draw(ax)\n",
    "\n",
    "    if prev_elements != None:\n",
    "        print i\n",
    "        cu.draw_transition(prev_elements, current_elements, transition, ax)\n",
    "        \n",
    "    prev_elements = current_elements\n",
    "    current_df, transition = cu.get_next_clusters(current_df, min_likelihood=.2)\n",
    "    datestr = dateutil.parser.parse(current_df['date'].iloc[0]).strftime('%B %d %Y')\n",
    "    ax.text(center, bottom, datestr, va='top', ha='center', transform=None, fontsize=14)\n",
    "\n",
    "ax.set_axis_off()\n",
    "ax_test.set_axis_off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
